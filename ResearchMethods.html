<!DOCTYPE HTML>
<!--
	Forty by HTML5 UP
	html5up.net | @ajlkn
	Free for personal and commercial use under the CCA 3.0 license (html5up.net/license)
-->
<html>
	<head>
		<style>
.sidenav {
  height: 100%;/* Full-height: remove this if you want "auto" height */
  width: 160px; /* Set the width of the sidebar */
  position: fixed; /* Fixed Sidebar (stay in place on scroll) */
  z-index: 1; /* Stay on top */
  top: 10%; /* Stay at the top */
  left: 0;
  background-color: #111; /* Black */
  overflow-x: hidden; /* Disable horizontal scroll */
  padding-top: 20px;
}

/* The navigation menu links */
.sidenav a {
  padding: 3px 8px 3px 16px;
  text-decoration: none;
  font-size: 15px;
  color: #818181;
  display: block;
}

/* When you mouse over the navigation links, change their color */
.sidenav a:hover {
  color: #f1f1f1;
}

.main {
  margin-left: 160px ;
}

.alt style2 {
  margin-left: 160px ;
}



/* Style page content */


/* On smaller screens, where height is less than 450px, change the style of the sidebar (less padding and a smaller font size) */
@media screen and (max-height: 450px) {
  .sidenav {padding-top: 15px;}
  .sidenav a {font-size: 12px;}
}
	</style>
		<title>Nicholas Bandy</title>
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
		<link rel="stylesheet" href="assets/css/main.css" />
		<noscript><link rel="stylesheet" href="assets/css/noscript.css" /></noscript>
	</head>
	<!-- Side navigation -->
<div class="sidenav">
  <a href="#ethics_reflection">Ethics In Computing Reflection</a>
  <a href="#discussion_1_initial">Discussion 1 Initial Post</a>
  <a href="#discussion_1_peer">Discussion 1 Peer Response</a>
  <a href="#discussion_1_summary">Discussion 1 Summary</a>
  <a href="#questionnaire">Questionnaire Review</a>
  <a href="#kmeans">K-Means</a>
  <a href="#discussion_2_initial">Discussion 2 Initial Post</a>
  <a href="#discussion_2_peer">Discussion 2 Peer Response</a>
  <a href="#discussion_2_initial">Discussion 2 Summary</a>
  <a href="#model_eval">Model Evaluation</a>
  <a href="#assignment2">Assignment 2</a>
  <a href="#finalreflection">Final Reflection</a>
</div>
	<body class="is-preload">
		<!-- Wrapper -->

				<!-- Header -->
				<!-- Note: The "styleN" class below should match that of the banner element. -->
					<header id="header" class="alt style2">
						<a href="index.html" class="logo"><strong>Nicholas Bandy</strong></a>
						<nav>
							<a href="#menu">Menu</a>
						</nav>
					</header>

				<!-- Menu -->
					<nav id="menu">
						<ul class="links">
							<li><a href="index.html">Home</a></li>
							<li><a href="dbd.html">Deciphering Big Data</a></li>
							<li><a href="MachineLearning.html">Machine Learning</a></li>
							<li><a href="ResearchMethods.html">Research Methods</a></li>
						</ul>
						
					</nav>

				<!-- Banner -->
				<!-- Note: The "styleN" class below should match that of the header element. -->
					<section id="banner" class="style2">
						<div class="inner">
							<span class="image">
								<img src="images/pic07.jpg" alt="" />
							</span>
							<header class="major">
								<h1>Research Methods</h1>
							</header>
						</div>
					</section>

				<!-- Main -->
					<div id="main" class="main">

						<section id="ethic_reflection">
								<div class="inner">
									<header class="major">
										<h2>Ethics In Computing Reflection</h2>
									</header>
									<p>As the capabilities of technology continue to advance, ethics in computing becomes an increasingly relevant topic. According to Stahl et al (2016), privacy is a dominant ethical concern. In my experience working for Calgary Transit, a public transit agency, we have to be mindful of the impacts of collecting any data that could be used to identify a person. This goes beyond just making sure that all activities are legal, but also ensuring that the organization maintains public trust.</p>
									<p>An example of this concern could be the desire for the organization to gather data regarding both origin and the final destination of passengers utilizing the transit network, so that it can be optimized to provide the public with the best possible service. With CCTV cameras in place on all vehicles and at train stations, there is the possibility of utilizing these cameras to perform facial recognition and track a persons movement through the transit network. The system would temporarily store data for a persons face at the departure location, and use that to match them to where they are last seen as their final destination. After not being seen for a certain amount of time, the departue and destination locations and times would be saved, while all data related to the person would be deleted. While the idea is simple and straightforward to implement, there are many concerns and roadblocks in developing this system.</p>
									<p>While it is not prohibited under Canada’s data privacy act PIPEDA (2019), or Alberta’s Freedom of Information and Privacy Act (2023) to use facial recognition for this purpose, a few important steps are required to ensure it does not infringe on the publics rights. Being a public service, the cameras are located on public property and not private property. Lack of transparency and knowledge of an active facial recognition system is among the leadings concerns around the implementation of these systems (Solarova et. Al, 2023), which is especially important when considering that this would be occuring in a public space instead of on private property. Therefore, it would be important to make sure that all passengers were made aware of the fact that this data collection was occuring. This could be done through the use of signs, and company announcements to the public to make sure that they know of this data collection.</p>
									<p>Another important component of this system is to ensure that peronal information such as the data used to match a persons face, is only being kept for as long as it is necessary. Minimizing the amount of time this information is held reduces the impact of any potential attack, and ensures that any identifying information is not being held so that it is not possible to be used later in a different application. This anonymization of the data helps to comply with legislation such as GDPR (Siegert et al, 2020), or in this case PIPEDA and Freedom of Information and Privacy Act, as once the individual is no longer identifiable it is not considered personal data. My recommendation to ensure that this is met is to remove all of the personal data once a person has not been seen in the network for 45 minutes, as at that point it is assumed that their trip has ended and they’ve reached their destination. At this point the origin and destination locations and times can be extracted without any further need to identify the individual.</p>
<p>Finally, Calgary Transit would need to ensure that the facial recognition was only being used for the purpose that they have advertised, which is to better understand origin and destination of travellers utilizing the network. Controlling the way in which personal data is used is an effective method  of ensuring data privacy conditions are met (Landau, 2015), and can help to ensure the organization complies with PIPEDA. This system would likely gain attraction and demand from other interested departments within the city such as law enforcement, but allowing them access to this system to identify and track criminals or suspicous individuals would violate the privacy act, as the personal data is no longer being used for the purpose that it was advertised and collected for.</p>
									<p>While following all of these steps would have ensured that the collection and use of this data complied with all data privacy laws here in Alberta, my recommendation would be to continue searching for an alternative technology that is less invasive, and to continue with their current method of using infrared cameras to track boardings and alightings for now as no personal data is gathered from that system. Informing the public of the decision to use facial recognition would harm the reputation of the organization, and likely cause backlash from riders who have concerns about the use of the technology. The negative impact that this would have on the organization outweighs the positive of having better data for improving the transit network. While gaining origin and destination data could have significant benefits to how Calgary Transit is able to best serve their customers, this collection may be better suited to a tap on, tap off payment system as it will not involve the same level of surviellance and monitoring in public spaces as facial recognition does.</p>
									
							<p>References</p>

<p>Government of Alberta. (2023). Freedom of Information and Privacy Act. Available From: https://www.alberta.ca/freedom-of-information-and-protection-of-privacy</p>
<p>Government of Canada. (2019). Personal Information Protection and Electronic Documents Act. Available From: https://laws-lois.justice.gc.ca/eng/acts/P-8.6/index.html</p>
<p>Landau, S. (2015). Control Use of Data to Protect Privacy. Available From: https://www-science-org.uniessexlib.idm.oclc.org/doi/10.1126/science.aaa4961</p>
<p>Siegert, I., Varod, V., Carmi, N., Kamocki, P. (2020). Personal data protection and academia: GDPR issues and multi-modal data-collections "in the wild". Online Journal of Applied Knowledge Management. Available from https://doi.org/10.36965/ojakm.2020.8(1)16-31.</p>
<p>Solarova, S., Podrouzek, J., Mesarcik, M., Gavornik, A., Bielikova, M. (2023). Reconsidering the regulation of facial recognition in public spaces. AI and Ethics, 3 (2), 625–635. Available from https://doi.org/10.1007/s43681-022-00194-0.</p>
<p>Stahl, B.C., Timmermans, J. and Mittelstadt, B.D.. (2016). The Ethics of Computing. ACM Computing Surveys, 48 (4), 1–38. Available from https://doi.org/10.1145/2871196.</p>
								</div>
							</section>

						<!-- One -->
							<section id="discussion_1_initial">
								<div class="inner">
									<header class="major">
										<h2>Discussion 1 Initial Post</h2>
									</header>
									<p>Case Study: Malware</p>

<p>In this case study, Rogue services is a cheap web hosting company used by botnets to protect their servers from take down attempts while spreading malware and spam. Increased malware distribution is a challenge for IT and can often cause losses in terms of time and resources (IT Professional, 2005)</p>
									
<p>By protecting these malicious services, Rogue was not acting in the best interests of the public. Despite this, the actions taken to take down Rogues network caused the loss of data for other legitimate parties that were using Rogues services responsibly. This makes it difficult to say whether the actions taken were ethical or the correct professional action, as the extent of damage caused by allowing the service to stay online vs the damage caused to innocent clients when taking it down changes in each scenario like this and needs to be carefully measured. The parties involved can justify their actions by stating that what they did was in the best interests of the public, and the ACM Code (Association for Computing Machinery, 2018) considers this scenario in section 2.8 if the reasons are for the best interest of the public. The BCS code (British Computer Society, 2022) does not specify the ability to perform these actions even if it’s in the publics best interest, and leaves it up to interpretation on if this action would be allowed. Had further steps been taken to allow clients to keep their data before taking down Rogues services, less harm would have come to the legitimate clients.</p>

<p>From the legal point of view, the country that Rogue was hosted in did not have laws preventing this type of hosting activity, therefore it is important that the vendors involved had the support of their respective governments. While this may give them the authorization to proceed, there is still the need to consider that the attack could violate the code by having negative consequences on their reputation and the reputation of the profession, especially since innocent customers were affected.</p>
									
<p>In summary, the scenario in this case study highlighted the complexity of interpreting these codes in difficult situations, and the importance of considering all consequences before taking any action. The legal and ethical responsibilities are left to the interpretation of what is considered to be in the 'publics best interest', and it is important to ensure that all relevant authorities also interpret these actions to be in the publics best interest before proceeding.</p>
  

<p>References</p>

<p>Association for Computing Machinery (2018) ACM Code of Ethics and Professional Conduct. Available from: https://www.acm.org/code-of-ethics</p>

<p>Association for Computing Machinery (N.D.) Case: Malicious Inputs to Content Filters. Available from: https://ethics.acm.org/code-of-ethics/using-the-code/case-malware-disruption/</p>

<p>British Computer Society (2022) Code of Conduct for BCS Members. Available from: https://www.bcs.org/media/2211/bcs-code-of-conduct.pdf </p>

<p>IT Professional (2005) Spike in phishing and malware a danger to IT, Available From: https://ieeexplore-ieee-org.uniessexlib.idm.oclc.org/document/1490465</p>									
								</div>
							</section>

						<!-- Two -->
						<section id="discussion_1_peer">
								<div class="inner">
									<header class="major">
										<h2>Discussion 1 Peer Response</h2>
									</header>
									<p>Hi Leigh, I enjoyed reading your comments, especially regarding who should be held accountable for failing to adhere to the principles. While I can also understand a developer doing as he’s told once his concerns are dismissed, the same could be argued for the development agency. At the end of the day, they are both just doing what they are told in order to generate income. I do agree with you that despite this, both the developer and the agency should be held accountable for failing to adhere to the principles.</p>
									

									<p>From a legal standpoint, it is likely only the client would have legal implications as they are the ones misleading consumers and adding hidden charges without permission such as the protection plan. However, from a professional and ethical standpoint the developer and agency were aware of how their work would be used to manipulate consumers and completed the job anyways. As stated previously this is in clear violation of the sections of both the BCS and ACM codes regarding public interest and professional integrity, while also potentially bringing the reputation of the profession into disrepute.</p>
									
									<p>In summary, while I do understand that the developer and agency were only making the changes as they were told in order to satisfy a client, I don’t believe this is a good justification for ignoring the principles set out in the code of conduct as they were aware of the potential damages.</p>
									
<p>References</p>

<p>Association for Computing Machinery (N.D.) Case: Dark UX Patterns. Available from: https://ethics.acm.org/code-of-ethics/using-the-code/case-dark-ux-patterns/</p>
<p>Association for Computing Machinery (2018) ACM Code of Ethics and Professional Conduct. Available from: https://www.acm.org/code-of-ethics</p>
<p>British Computer Society (2022) Code of Conduct for BCS Members. Available from: https://www.bcs.org/media/2211/bcs-code-of-conduct.pdf</p>
						
								</div>
							</section>

<!-- Two -->
						<section id="discussion_1_summary">
								<div class="inner">
									<header class="major">
										<h2>Discussion 1 Summary</h2>
									</header>
									<p>In my initial post I provided a summary of the malware case study in which Rogue Services was hosting malicious content that spread malware and spam, and were forcibly taken down in a joint effort through vendors and government agencies. I stated that that while Rogue was not following the ACM (Association for Computing Machinery, 2018) and BCS (British Computer Society, 2022) codes by not acting in the publics best interests, the effort to take them down was and therefore could be seen as following the guidelines. This opens a debate as to who decides what's in the publics best interest, as innocent and legitimate businesses lost their data and were affected in the process.</p>
									<p>In discussion with my colleagues, it was mentioned that disabling Rogues services without safeguarding the legitimate data shows a lacking risk assessment, and could bring their reputation into disrepute. It also suggests issues around professional competence for this task, and would violate both the ACM and BCS codes. We also discussed how it can be difficult to weigh ethics against the outcome in cybersecurity, as sometimes the best outcome for most of the public can involve harming other innocent users. These discussions have helped to emphasize the importance of proper planning and risk assessment when dealing with cyber security issues, as unforeseen issues or consequences such as innocent users losing their data can have repercussions and bring professional competence into question.</p>
							<p>References</p>

<p>Association for Computing Machinery (2018) ACM Code of Ethics and Professional Conduct. Available from: https://www.acm.org/code-of-ethics</p>
<p>Association for Computing Machinery (N.D.) Case: Malicious Inputs to Content Filters. Available from: https://ethics.acm.org/code-of-ethics/using-the-code/case-malware-disruption/</p>
<p>British Computer Society (2022) Code of Conduct for BCS Members. Available from: https://www.bcs.org/media/2211/bcs-code-of-conduct.pdf</p>
								</div>
							</section>
						
						<!-- Three -->
						<section id="questionnaire">
								<div class="inner">
									<header class="major">
										<h2>Questionnaire Review</h2>
									</header>
									<p>The assignment for this week is to find and critique a questionnaire. The River Access Strategy Questionnaire from the City of Calgary (2016) was looking for feedback based on available boat and hand launch sites along the Bow River in the city. The target audience for this questionnaire looks to be residents in Calgary that use the rive for activities such as rafting, boating, or kayaking, which require a place to launch. The questionnaire consists of 10 open questions where the respondent can type their anwser, primarily focusing on the locations of launch sites along the river, and other requirements or suggestions of anything that should be included at or near the launch sites.</p>

									<p>The open questions give the respondent the opportunity to express their feelings and share detailed information regarding the city’s plan, however I feel that the city could improve on the questionnaire by adding in some closed questions to gain categorical data. An example of this would be to understand how the respondent is travelling to the launch points (car, bike, walk, etc.), as it could affect their view on requirements such as parking. Additionally, understanding how frequently they use a launch site, or what type of watercraft they are launching, may provide deeper insights into specific challenges that affect these groups of people.</p>
									
									<p>References</p>

<p>City of Calgary (2016). River Access Strategy Questionnaire. Available From: https://engage.calgary.ca/riveraccess/river-access-strategy-questionnair</p>
								</div>
							</section>

						<!-- Three -->
						<section id="literature_review">
								<div class="inner">
									<header class="major">
										<h2>Literature Review</h2>
									</header>
									<p> <a href="https://shabal.in/visuals/kmeans/1.html">The first kmeans visual</a> shows a distribution of data points and how the algorithm is affected by the starting point. Starting with the four points furthest left for the first run, furthest top for the second, furthest right for the fourth, and furthest bottom for the fourth. Only one of these gave the result of the 4 clusters that I had expected to see looking at the data points before the algorithm ran. This showed that picking the extremes as starting points can affect how the clusters are formed, as sometimes they would end up with small clusters preventing a centroid from moving closer to where it would give the most accurate match. The final run uses random starting points and does end up with the expected clusters, as the starting points are not at the extremes of the data set.</p>
				<p> <a href="https://www.naftaliharris.com/blog/visualizing-k-means-clustering/">For the second kmeans visual</a> we were to choose our own points for a uniform distribution of data. Regardless how many clusters I chose to have or where I picked to initialize them, I always finished with the same equal clusters. This highlighted the effect that the dataset has on an algorithm, and that for the uniform dataset the starting points were not important as it always came to the same result. </p>
				<p>This exercise was very useful in providing a visual sample on how different starting points and data distributions can change the final clusters. Uniform data gives the impression that the clusters will always turn out the same, however seeing the first visual go through the stages of clustering from different starting places highlights the fact that the k-means algorithm will converge to a minima, but it may not be the same one as it would if it started from a different position.</p>					
								</div>
							</section>

						<!-- Two -->
						<!-- One -->
							<section id="discussion_2_initial">
								<div class="inner">
									<header class="major">
										<h2>Discussion 2 Initial Post</h2>
									</header>

<p>Abi is obligated to present both the positive and negative results, regardless of how they are presented by the manufacturer going forward. Anything else would be intentionally hiding data to support a particular stance, which is unethical and could have a negative impact on both his and his institutes reputation. If Abi only shared partial results, he would be contributing to a loss in knowledge on the product (Sabatello et. Al, 2022). While Abi believes that Whizzz would only publicize the positive results, having the negative results shown to them could help them better understand their product and be used to make improvements, even if they’re not shared with the public.</p>					
<p>Abi is not responsible for how Whizzz decides to share the results of the study, but can take steps to mitigate the impact of Whizzz only sharing selective results. Including all results in both his report and any report published by the research institution means that while Whizzz can selectively share positive results from the report, they cannot directly share the report from the institution without showing all results. Given that this seems to be a study funded by Whizzz, Abi and the research institution should have a data sharing agreement in place with Whizzz before beginning the study to allow them to publish and share the results, regardless of what they turn out to be.</p>

<p>References</p>

<p>Sabatello, M., Martschenko, D., Cho, M., Brothers, K. (2022)  Data sharing and community-engaged research: Data sharing must be accompanied by responsibility sharing. Science (American Association for the Advancement of Science). Available From: https://web-p-ebscohost-com.uniessexlib.idm.oclc.org/ehost/pdfviewer/pdfviewer?vid=0&sid=b5334d05-bef4-44bc-8ce0-a9aef4fee78b%40redis</p>
								
								</div>
							</section>

						<!-- Two -->
						<section id="discussion_2_peer">
								<div class="inner">
									<header class="major">
										<h2>Discussion 2 Peer Response One</h2>
									</header>
									<p>Hi Ruth, Thank you for your post. While I agree with most of what you’ve said, I do believe that their can be a case Whizzz having both positive and negative correlations with a persons health. The wording in the post is not very specific as you mentioned, saying that Whizzz could be seen as nutritious or harmful depending on how the data is presented. The same could be said about dried fruits, which have many nutrients and fibres to be considered nutritious, yet the high sugar content could be harmful to dental health (Sadler et. Al, 2019). This doesn’t necessarily mean that the results are inconclusive, but that the nutritional benefits and potential harmful effects of Whizzz could be unrelated or circumstantial (ie. Overconsumption)</p>

									<p>The wording in the case study makes it difficult to know if this is the case, but regardless of this I agree that the final decision on how to manage the information should be handled by management and not by Abi. By reporting all of his findings Abi ensures that he is protecting both himself and the research institution should their be any investigations based on the reports Whizzz publishes from this data.</p>
<p>References</p>

<p>Sadler, M., Gibson, S., Whelan, K., Ha, M., Lovegrove, J., Higgs, J. (2019) Dried fruit and public health – what does the evidence tell us?, International Journal of Food Sciences and Nutrition, Available From: https://doi.org/10.1080/09637486.2019.1568398</p>

						
								</div>

							<div class="inner">
									<header class="major">
										<h2>Discussion 2 Peer Response Two</h2>
									</header>
									<p>Hi Samuel, thank you for your thoughtful post. You are right in saying that the research’s integrity is undermined if the full results aren’t reported. This reporting bias leads to a different story being told instead of the reality, and therefore all results should be published regardless of if they are negative, positive, or seem non-significant at the time (Dawson & Dawson, 2018). The results may become more significant as further studies are done, but will not be realized if they are excluded from the report because they were not judged to be important. As you mentioned reporting all results can help to protect Abi and the research institution in the case of an investigation into any results that Whizzz decides to make public. Having a record that all results were shared and not just the positive ones that Whizzz publicized ensures that even though Whizz did not act ethically, Abi and the institution did.</p>
									
								<p>References</p>

<p>Dawson, P. and Dawson, S.L.. (2018). Sharing successes and hiding failures: ‘reporting bias’ in learning and teaching research. Studies in Higher Education, 43 (8), 1405–1416. Available from https://doi.org/10.1080/03075079.2016.1258052.</p>

						
								</div>
							</section>

<!-- Two -->
						<section id="discussion_2_summary">
								<div class="inner">
									<header class="major">
										<h2>Discussion 2 Summary</h2>
									</header>
									<p>In my initial post I stated that Abi is obligated to present all results, regardless if they’re positive or negative for Whizzz. Withholding some results would be dishonest and unethical, and could also cause a loss of knowledge related to the product (Sabatello et. Al, 2022). As mentioned by my peers, presenting all results protects Abi from the potential consequences of covering up potential harm of the product (Buzby et. Al, 2001). If Whizzz makes false claims about the product they would breach food safety standards (FSA, 2023), and presenting all results protects Abi in the case of an investigation.</p>
									<p>In all of our discussions there are no arguments for Abi to withhold any of the results for Whizzz, highlighting ethics and self-protection as the key reasons. I also stated that Abi should have taken additional steps to prevent this ethical dilemma before starting the project. Considering that it was funded by Whizzz, Abi should have identified this potential issue before starting and made an agreement about publishing the full data results. We were all in agreement that any decision by Whizzz to only share positive outcomes of the report is not Abi’s responsibility, as long as he was thorough in his report and included all of his findings.</p>
							<p>References</p>

<p>Buzby, J.C., Frenzen, P.D. and Rasco, B., 2001. Product Liability and Microbial Foodborne Illness. Agricultural Economic Report No. 799. Food and Rural Economics Division, Economic Research Service, U.S. Department of Agriculture.</p>
<p>Food Standards Agency (2023) Packaging and Labelling. Available from https://www.food.gov.uk/business-guidance/packaging-and-labelling#:~:text=1169%2F2011%2C%20the%20Food%20Information,%2C%20milk%2C%20fish%20and%20meat.</p>
<p>Sabatello, M., Martschenko, D., Cho, M., Brothers, K. (2022)  Data sharing and community-engaged research: Data sharing must be accompanied by responsibility sharing. Science (American Association for the Advancement of Science). Available From: https://web-p-ebscohost-com.uniessexlib.idm.oclc.org/ehost/pdfviewer/pdfviewer?vid=0&sid=b5334d05-bef4-44bc-8ce0-a9aef4fee78b%40redis</p>
								</div>
							</section>

<section id="discussion_2">
								<div class="inner">
									<header class="major">
										<h2>Discussion 2</h2>
									</header>
									<p>The popularity of AI tools such as Chat GPT has skyrocketed in recent years. It is easily accessible to most people and can be applied to a wide range tasks, creating potential use-cases in almost any industry.</p>
  <p>These tools can be useful in terms of increasing efficiency and reducing the manual workload involved in simple tasks such as creating a schedule or drafting a template for an email. Due to the diversity of training data it is also useful at providing insights on a wide range of topics that may prove useful in the task at hand (Zimmerman, 2023). It can also be useful to support the scientific writing process through brainstorming and experimental design (Ingley & Pack, 2023).</p>

<p>While there is a large range of benefits, the discussions with my classmates focused more on the risks involved in using this technology incorrectly. Reliability of the answers provided is questioned due to the uncertainty on how information is gathered or where it came from (Castelvecchi, 2016), which also leads to potential bias in the data (Hutson, 2021). Finally the concerns were discussed around the loss of creativity (Sundar & Liao, 2023) and critical thinking skills (Arif et. Al, 2023) that could arise if users become too dependent on the technology.</p>									

									<p>While there are many risks, they can all be mitigated by a user using these AI tools correctly and responsibly. Proofreading and critically analyzing its output can catch any bias and help the user to understand the topic, and also allows the user to fact check the output. As adoption of AI tools continue to grows it will be important to educate the users on the best way to use them and of the risks involved with using them incorrectly.</p>
									
<p>References</p>

<p>Arif, T. B., Munaf, U., and Ul-Haque, I. (2023). The future of medical education and research: Is ChatGPT a blessing or blight in disguise?. Medical education online, 28(1 Available From: https://www.tandfonline.com/doi/full/10.1080/10872981.2023.2181052</p>

<p>Castelvecchi, D. (2016) Can we open the black box of AI. Nature 538, 20–23, Available From: https://www.nature.com/news/can-we-open-the-black-box-of-ai-1.20731</p>

<p>Hutson, M. (2021). Robo-writers: the rise and risks of language-generating AI. Nature 591, 22-25, Available From: https://www.nature.com/articles/d41586-021-00530-0</p>

<p>Ingley, S., Pack, A. (2023) Leveraging AI tools to develop the writer rather than the writing, Trends in Ecology & Evolution, Volume 38, Issue 9, Pages 785-787, ISSN 0169-5347, Available From: https://doi.org/10.1016/j.tree.2023.05.007</p>									
								<p>Sundar, S. S., & Liao, M. (2023). Calling BS on ChatGPT: Reflections on AI as a Communication Source. Journalism & Communication Monographs, 25(2), 165-180. Available From: https://doi-org.uniessexlib.idm.oclc.org/10.1177/15226379231167135</p>
								<p>Zimmerman, A. (2023). A Ghostwriter for the Masses: ChatGPT and the Future of Writing. Annals of surgical oncology, 1-4. Available From: https://link-springer-com.uniessexlib.idm.oclc.org/article/10.1245/s10434-023-13436-0</p>
								</div>
							</section>

						<section id="seminar_5">
								<div class="inner">
									<header class="major">
										<h2>Seminar 5</h2>
									</header>
									<p>The article by Mach (2021) discusses how neural networks are applied in e-commerce, finance, healthcare, security, and logistics. While I don’t have any experience working within these fields, I’m interested in the way that neural networks are applied in healthcare. A high level of accuracy is required to depend on a neural network for making a diagnosis based on medical imaging, yet faces a challenge of overfitting in some classification tasks due to a limited number of training samples (Egger et. Al, 2022). As the amount of training data continues to grow and improved models are trained, I expect that neural networks will continue to be adopted to tackle new issues in the healthcare field.</p>
  <p>The snapshot paper (UK Government, 2019) discusses the ways in which AI is currently and can be used in the insurance industry. While I was aware of possible benefits of using AI to find fraudulent claims and reduce price for policyholders, I never considered that decisions could be made based on inferred data such as assuming somebody exercises because they bought running shoes, or that the technology would be used to get a customer to pay the highest premium that AI believes they’d be willing to pay, instead of giving them a price based on the risk assessment done by AI. Thinking of these possibilities emphasizes the importance of ensuring that personal data is used properly and only when necessary, not to take advantage of an individual.</p>
<p>The two assigned papers for this activity brought forth some ethical challenges that the industry is faced with. Reading through them made me think about what I plan to do with the skills I learn from this course, and the type of projects that I would be happily involved in. I believe this will help me to consider all implications of my work before proceeding with future projects.</p>
<p>References</p>

<p>Egger, J., Gsaxner, C.,  Pepe, A., Pomykala, K., Jonske, F., Kurz, M., Li, J., Kleesiek, J. (2022) Medical deep learning—A systematic meta-review, Computer Methods and Programs in Biomedicine, Volume 221, Available From : https://doi.org/10.1016/j.cmpb.2022.106874.</p>

<p>Mach, P. (2021). 10 Business Applications of a Neural Network, Available From: https://www.ideamotive.co/blog/business-applications-of-neural-network</p>

<p>UK Government, (2019). Snapshot Paper – AI and Personal Insurance. Available From: https://www.gov.uk/government/publications/cdei-publishes-its-first-series-of-three-snapshot-papers-ethical-issues-in-ai/snapshot-paper-ai-and-personal-insurance</p>

</div>
							</section>

						<section id="CNN's">
								<div class="inner">
									<header class="major">
										<h2>CNN's</h2>
									</header>
									<p>The article by Wall (2019) highlighted the ethical dilemmas around face recognition technology due to a lack of accuaracy and known bias within the system. It states training sets are unbalanced, and that individuals with darker skin tones are more likely to be misidentified. For applications such as the one discussed in the article of attempting to detect a potential threat, this bias is greatly problematic and should prevent the technology from being used in its current state. Applying face recognition technology in this manner could also cause great concern about protection of privacy and personal data, as implementing systems to track and identify threats would also be capable of tracking and following all people passing through.</p>
  <p>The second task was to review the sample code provided. The first sections import libraries and perform basic tasks such as splitting the data into a train and test set, determining the shape of each data set, and the size of the images. A validation set is then created, which is used to fine tune hyperparameters after the initial training (Pramoditha, 2022).</p>
<p>Next the model is created, consisting for of two sets of alternating convolutional layers and pooling layers, before being flattened and having two fully connected layers at the end. The last fully connected layer uses softmax as the probability of each class to produce an output.</p>
	<pre><code>model = Sequential()

## ************* FIRST SET OF LAYERS *************************

# CONVOLUTIONAL LAYER
model.add(Conv2D(filters=32, kernel_size=(4,4),input_shape=(32, 32, 3), activation='relu',))
# POOLING LAYER
model.add(MaxPool2D(pool_size=(2, 2)))

## *************** SECOND SET OF LAYERS ***********************
#Since the shape of the data is 32 x 32 x 3 =3072 ...
#We need to deal with this more complex structure by adding yet another convolutional layer

# *************CONVOLUTIONAL LAYER
model.add(Conv2D(filters=32, kernel_size=(4,4),input_shape=(32, 32, 3), activation='relu',))
# POOLING LAYER
model.add(MaxPool2D(pool_size=(2, 2)))

# FLATTEN IMAGES FROM 32 x 32 x 3 =3072 BEFORE FINAL LAYER
model.add(Flatten())

# 256 NEURONS IN DENSE HIDDEN LAYER (YOU CAN CHANGE THIS NUMBER OF NEURONS)
model.add(Dense(256, activation='relu'))

# LAST LAYER IS THE CLASSIFIER, THUS 10 POSSIBLE CLASSES
model.add(Dense(10, activation='softmax'))


model.compile(loss='categorical_crossentropy',
              optimizer='adam',
              metrics=['accuracy'])
model.summary()</code></pre>
									<img src="images/unit9cnn.PNG" alt="Diagram" style="width:30%">
									<figcaption>Figure 1: sample CNN structure</figcaption>
									<p>Testing the model on the test dataset gives an accuracy of 66%, with highly varied results for each target class.</p>
	<img src="images/testunit9cnn.PNG" alt="Diagram" style="width:30%">
									<figcaption>Figure 2: Test data results</figcaption>
									<p>I tested this model on images 13, 11, 4, and 5 which were correctly classified as a horse, truck, frog, and frog respectively, however testing on image 6 returned frog when it should be a car.</p>								
<p>Reviewing this CNN is an important activity for this module, as it directly relates to what we will be doing the second assessment. The CNN architecture applied to the CIFAR-10 dataset here shows that there is much opportunity for improvement, which I'm certain we will achieve in the assignment. Viewing and testing different images gave useful insight into the decision-making of the network, such as a car being classified as a frog likely due to its block-like shape as opposed to the long trucks in other images.</p>
									<p>References</p>

<p>Pramoditha, R. (2022)  Why do we need a validation set in addition to training and test sets?  Available from: https://towardsdatascience.com/why-do-we-need-a-validation-set-in-addition-to-training-and-test-sets-5cf4a65550e0</p>

<p>Wall, N. (2019) Biased and Wrong? Facial Recognition Tech in the Dock. Available From: https://www.bbc.co.uk/news/business-48842750</p>

</div>
							</section>

<section id="model_eval">
								<div class="inner">
									<header class="major">
										<h2>Model Evaluation</h2>
									</header>
									<p>In this assignment we are changing parameters in the model performance python file to observe the impacts on the AUC score and R2 score. The portion of the code used is shown below, and gives an AUC score of 0.79, and an R2 score of -0.28.</p>
<pre><code>import numpy as np
import matplotlib.pyplot as plt
from itertools import cycle

from sklearn import svm, datasets
from sklearn.metrics import roc_curve, auc
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import label_binarize
from sklearn.multiclass import OneVsRestClassifier
from sklearn.metrics import roc_auc_score
from sklearn.metrics import r2_score

# Import some data to play with
iris = datasets.load_iris()
X = iris.data
y = iris.target

# Binarize the output
y = label_binarize(y, classes=[0, 1, 2])
n_classes = y.shape[1]

# Add noisy features to make the problem harder
random_state = np.random.RandomState(0)
n_samples, n_features = X.shape
#X = np.c_[X, random_state.randn(n_samples, 200 * n_features)]

# shuffle and split training and test sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=0)

# Learn to predict each class against the other
classifier = OneVsRestClassifier(
    svm.SVC(kernel="linear", probability=True, random_state=random_state)
)
y_score = classifier.fit(X_train, y_train).decision_function(X_test)

# Compute R2 score - added by Nicholas
y_pred = classifier.predict(X_test)
print(r2_score(y_test,y_pred))

# Compute ROC curve and ROC area for each class
fpr = dict()
tpr = dict()
roc_auc = dict()
for i in range(n_classes):
    fpr[i], tpr[i], _ = roc_curve(y_test[:, i], y_score[:, i])
    roc_auc[i] = auc(fpr[i], tpr[i])

# Compute micro-average ROC curve and ROC area
fpr["micro"], tpr["micro"], _ = roc_curve(y_test.ravel(), y_score.ravel())
roc_auc["micro"] = auc(fpr["micro"], tpr["micro"])</code></pre>
									<img src="images/noisyAUC.png" alt="Diagram" style="width:75%">
									<figcaption>Figure 1: AUC with default noisy data</figcaption>
									<br>
									<p>The low scores were likely due to the noisy features that were added to make this more difficult, so the first thing I’ve tried is to remove the noise and observe the performance. Removing the noise gives an R2 score 0f 0.5, and an AUC score of 1.</p>
<img src="images/nonoiseAUC.png" alt="Diagram" style="width:75%">
									<figcaption>Figure 2: AUC with noise removed from data</figcaption>
									<br>
									<p>Finally, I’ve tried reducing the multiplier on the noise from 200 to 20. This gave an R2 score of 0.27 and an AUC score of 0.88.</p>								
<img src="images/smallnoiseAUC.png" alt="Diagram" style="width:75%">
									<figcaption>Figure 3: AUC with decreased noise in data</figcaption>
									<br>
									<p>Putting these together, we can see that having more noise in the data lowers both the AUC and the R2 score, while the cleaned data increases both the AUC and R2 score. The AUC score is directly related to the number of true positives and false positives in the dataset (Nighania, 2018), and without noise contains less false positives. According to Jordan (2017), “ The R2 coefficient represents the proportion of variance in the outcome that our model is capable of predicting based on its features.” This is why even though we obtain an almost perfect AUC value, the R2 error can still show a lower value, as it also considers the false negatives.</p>
									<p>This assignment demonstrated different ways to evaluate a machine learning model, as accuracy isn’t the only measure that can be useful. I expect to use these in the assignment submission this week to measure our models perfomance, and also that these will be useful in the future when trying to gain deeper insights about a models performance.</p>
									<p>References</p>

<p>Jordan, J. (2017) Evaluating a machine learning model. Available From: https://www.jeremyjordan.me/evaluating-a-machine-learning-model/</p>

<p>Nighania, K. (2018) Various ways to evaluate a machine learning models performance. Available From: https://towardsdatascience.com/various-ways-to-evaluate-a-machine-learning-models-performance-230449055f15</p>

</div>
							</section>
						
						<section id="assignment2">
<div class="inner">
									<header class="major">
										<h2>Assignment 2</h2>
									</header>
									<p>The second assignment for this course was to train a CNN using the CIFAR-10 dataset. After having overlapping tasks within our group on the first assignment, we attempted to equally divide the work ahead of time. My role was to introduce the project and write the background information about the structure of a CNN. Additionally, I helped to set up the google colab space with a sample cnn from the unit 9 activity so that group members had a starting point for their section, and helped to troubleshoot any issues in the code.</p>
  <p>Focusing on the structure of a CNN, I researched and discussed the typical structure of CNN’s, the purpose and function of each layer, and how they are combined together. This helped to deepen my understanding of the network architecture. I believe that this project would be a great learning opportunity if done individually, however having large groups made it unnecessarily complicated. I look forward to applying the knowledge from this assignment into my future projects.</p>


	<p><a href="https://github.com/Nicholas-Bandy/eportfolio/blob/main/Presentation Transcript.docx">View the transcript here</a></p>

</div>
							</section>

						</section>

						<section id="finalreflection">
<div class="inner">
									<header class="major">
										<h2>Final Reflection</h2>
									</header>
									<p>During this module studies focused on the underlying theories and practices involved in machine learning. Beginning with a review of the exploratory data analysis (EDA) process, we worked our way through examples of correlation and regression, before beginning with unsupervised machine learning in the form of clustering. In the second half of the module we focused on the theories and structure of artificial neural networks (ANN), and finally creating and evaluating our own Convolution Neural Network (CNN) model. Throughout this process there were many strong discussions about the moral and ethical dilemmas surrounding the current and potential use of machine learning and artificial intelligence.</p>
  <p>Having completed the numerical analysis module as a pre-requisite, I had a good understanding of the EDA process before beginning this module. The first few units provided a good opportunity to familiarize myself with EDA using python instead of R, and ensure that I was comfortable with the language before moving directly into new content. The same applies to the chapters on correlation and linear regression. Having this much repetition in content between different modules felt unnecessary, but provided an opportunity for me to ensure that there were no gaps in my knowledge before moving on.</p>
<p>During units 5 and 6 we learned about the logic behind clustering, and how/when it can be used in practice. The purpose of clustering is to group data points together based on similar traits (Bonthu, 2021) by minimizing the mean square distance to each point from the nearest centroid. Seeing the visuals from Harris (2014) and Shabalin go through what happened at each stage of the algorithm based on the selected starting positions was very useful to me in understanding how the clustering worked. With the understanding gained in these units I feel confident in applying clustering to a real life problem.</p>
<p>Our first assignment was to carry out EDA and perform unsupervised learning on the Airbnb dataset. My focus in this assignment was in performing EDA, and organizing the google colab space so that we could collaborate on the assignment. Given that our group consisted of 5 people all living and working full time jobs in different countries, we faced many challenges trying to find the best approach to our assignment. We utilized Google Colab and Microsoft Teams to try and ensure we could all work together on the same files, as dividing EDA and clustering between 5 people was not possible. The grouping for this module felt extremely unreasonable and added many unnecessary complications to the assignment, however I tried to use this as an opportunity to improve my project management and leadership skills under difficult circumstances.</p>
<p>After the assignment the focus shifted to ANN’s for the remainder of the course. Learning the theories and basic structure behind ANN’s built a strong foundation for the rest of the module, as having a deep understanding proved extremely useful in the later weeks. There were many discussions and assigned readings surrounding the ethical concerns surrounding both AI and machine learning. While concerns around bias and misinformation for models (Wall, 2019) such as chat GPT or facial recognition were well known to me, I never considered much about how a company could use the technology to take advantage of a customer. This could involve overcharging a customer based on pricing to what it thinks they’re willing to pay (UK Government, 2019), or adjusting the price of insurance based on inferred data instead of facts. These discussions were very eye-opening to me, and will make me consider the ethical consequence of any future project that I’m taking part in. </p>
<p>For the practical component of learning and training a model, the focus was on CNN’s. Image detection is a topic that I’m very excited about, and enjoyed having the opportunity not just to learn about it, but to work on and train my own model. Throughout this program I’ve sometimes found that it can be difficult to understand some of the concepts without seeing how they work, and just as in the clustering units I found that the CNN explainer (Wang et. al, 2020) was extremely helpful in understanding the stages of the CNN.</p>
<p>The second assignment for this course was to train a CNN using the CIFAR-10 dataset. Our group had the same issues as before trying to work on this project with so many of us, and without being able to align our times to work on it. We tried to learn from our struggles in the first assignment and divide up all of the tasks ahead of time, and my role was to introduce the project and write the background information about the structure of a CNN. Additionally, I organized the google colab space and ensured that the CNN from the unit 9 assignment was inserted as a starting point for other members to begin exploring their components of the assignment. Through my research to complete my component of the assignment, I gained a good understanding of each component of a CNN, and confidence in my ability to apply this to another dataset.</p>
<p>Coming into this module, I expected to learn how to apply machine learning theory to create working models on real datasets. I believe that I achieved that, yet I don’t feel that it was the most important thing that I learned during this module. The discussion forums and seminar assignments regarding ethical, and practical concerns surrounding AI and neural networks helped me to understand the importance of making sure that I use this technology correctly, and in a way that can be helpful to others instead of taking advantage of them. I expect that I will carry these ideas with me as I look to launch my career in this field.</p>

	<p>References</p>
	<p>Bonthu, H. (2021) Understanding KMeans Clustering for Data Science Beginners. Available from: https://www.analyticsvidhya.com/blog/2021/08/kmeans-clustering/</p>
	<p>Harris, N. (2014). Visualizing K-means Clustering. Available From: https://www.naftaliharris.com/blog/visualizing-k-means-clustering/</p>
	<p>Shabalin, A. K-means Clustering. Available From: https://shabal.in/visuals/kmeans/1.html</p>
	<p>UK Government, (2019). Snapshot Paper – AI and Personal Insurance. Available From: https://www.gov.uk/government/publications/cdei-publishes-its-first-series-of-three-snapshot-papers-ethical-issues-in-ai/snapshot-paper-ai-and-personal-insurance</p>
	<p>Wall, N. (2019) Biased and Wrong? Facial Recognition Tech in the Dock. Available From: https://www.bbc.co.uk/news/business-48842750</p>
	<p>Wang, J., Turko, R., Shaikh, O., Park, H., Das, N., Hohman, F., Kahng, M., Chau, P. (2020) CNN Explainer. Available From: https://poloclub.github.io/cnn-explainer/</p>
	
</div>
							</section>
						
				<!-- Contact -->
					<section id="contact">
						<div class="inner">
							<section>
								<form method="post" action="#">
									<div class="fields">
										<div class="field half">
											<label for="name">Name</label>
											<input type="text" name="name" id="name" />
										</div>
										<div class="field half">
											<label for="email">Email</label>
											<input type="text" name="email" id="email" />
										</div>
										<div class="field">
											<label for="message">Message</label>
											<textarea name="message" id="message" rows="6"></textarea>
										</div>
									</div>
									<ul class="actions">
										<li><input type="submit" value="Send Message" class="primary" /></li>
										<li><input type="reset" value="Clear" /></li>
									</ul>
								</form>
							</section>
							<section class="split">
								<section>
									<div class="contact-method">
										<span class="icon solid alt fa-envelope"></span>
										<h3>Email</h3>
										<a href="#">nicholasbandy1@gmail.com</a>
									</div>
								</section>
								
							</section>
						</div>
					</section>

				<!-- Footer -->
					<footer id="footer">
						<div class="inner">
							<ul class="icons">
								<li><a href="#" class="icon brands alt fa-twitter"><span class="label">Twitter</span></a></li>
								<li><a href="#" class="icon brands alt fa-facebook-f"><span class="label">Facebook</span></a></li>
								<li><a href="#" class="icon brands alt fa-instagram"><span class="label">Instagram</span></a></li>
								<li><a href="#" class="icon brands alt fa-github"><span class="label">GitHub</span></a></li>
								<li><a href="#" class="icon brands alt fa-linkedin-in"><span class="label">LinkedIn</span></a></li>
							</ul>
							<ul class="copyright">
								<li>&copy; Untitled</li><li>Design: <a href="https://html5up.net">HTML5 UP</a></li>
							</ul>
						</div>
					</footer>

			</div>

		<!-- Scripts -->
			<script src="assets/js/jquery.min.js"></script>
			<script src="assets/js/jquery.scrolly.min.js"></script>
			<script src="assets/js/jquery.scrollex.min.js"></script>
			<script src="assets/js/browser.min.js"></script>
			<script src="assets/js/breakpoints.min.js"></script>
			<script src="assets/js/util.js"></script>
			<script src="assets/js/main.js"></script>

	</body>
</html>
